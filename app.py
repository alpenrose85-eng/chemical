import streamlit as st
import pandas as pd
from docx import Document
import json
import os
from datetime import datetime
import io
from docx.shared import Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from docx.shared import Pt
import re
from difflib import SequenceMatcher

class SampleNameMatcher:
    def __init__(self):
        self.surface_types = {
            '–≠–ü–ö': ['–≠–ü–ö'],
            '–®–ü–ü': ['–®–ü–ü'],
            '–ü–° –ö–®': ['–ü–° –ö–®', '–ü–¢ –ö–®', '–ü–¢–ö–ú', '–ü–¢ –ö–ú', '–ü–¢–ö–ú'],
            '–ö–ü–ü –í–î': ['–ö–ü–ü –í–î', '–í–î'],
            '–ö–ü–ü –ù–î-1': ['–ö–ü–ü –ù–î-1', '–ö–ü–ü –ù–î-I', '–ù–î-1', '–ù–î-I'],
            '–ö–ü–ü –ù–î-2': ['–ö–ü–ü –ù–î-2', '–ö–ü–ü –ù–î-II', '–ù–î-2', '–ù–î-II']
        }
        self.letters = ['–ê', '–ë', '–í', '–ì']
        self.roman_to_arabic = {'I': '1', 'II': '2', 'III': '3', 'IV': '4'}
    
    def parse_correct_names(self, file_content):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            doc = Document(io.BytesIO(file_content))
            correct_names = []
            
            # –ü–∞—Ä—Å–∏–º —Ç–∞–±–ª–∏—Ü—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
            for table in doc.tables:
                for row in table.rows:
                    if len(row.cells) >= 2:  # –ö–∞–∫ –º–∏–Ω–∏–º—É–º 2 —Å—Ç–æ–ª–±—Ü–∞: –Ω–æ–º–µ—Ä –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        number_cell = row.cells[0].text.strip()
                        name_cell = row.cells[1].text.strip()
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                        if number_cell and name_cell and number_cell.isdigit():
                            correct_names.append({
                                'number': int(number_cell),
                                'original': name_cell,
                                'surface_type': self.extract_surface_type(name_cell),
                                'tube_number': self.extract_tube_number(name_cell),
                                'letter': self.extract_letter(name_cell)
                            })
            
            # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            if not correct_names:
                for paragraph in doc.paragraphs:
                    text = paragraph.text.strip()
                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º "—á–∏—Å–ª–æ   –Ω–∞–∑–≤–∞–Ω–∏–µ"
                    match = re.match(r'^\s*(\d+)\s+([^\s].*)$', text)
                    if match:
                        number = match.group(1)
                        name = match.group(2).strip()
                        if number.isdigit():
                            correct_names.append({
                                'number': int(number),
                                'original': name,
                                'surface_type': self.extract_surface_type(name),
                                'tube_number': self.extract_tube_number(name),
                                'letter': self.extract_letter(name)
                            })
            
            return correct_names
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ñ–∞–π–ª–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏: {str(e)}")
            return []
    
    def extract_surface_type(self, name):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –Ω–∞–≥—Ä–µ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        for surface_type, patterns in self.surface_types.items():
            for pattern in patterns:
                if pattern in name:
                    return surface_type
        
        # –ï—Å–ª–∏ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç, –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        for surface_type, patterns in self.surface_types.items():
            for pattern in patterns:
                if self.similar(pattern, name) > 0.7:  # 70% —Å—Ö–æ–∂–µ—Å—Ç–∏
                    return surface_type
        
        return None
    
    def similar(self, a, b):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫"""
        return SequenceMatcher(None, a, b).ratio()
    
    def extract_tube_number(self, name):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ —Ç—Ä—É–±—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"""
        # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ —Å–∫–æ–±–∫–∞—Ö –∏–ª–∏ –ø–æ—Å–ª–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–∏–ø–∞
        matches = re.findall(r'\((\d+)[,-]', name)
        if matches:
            return matches[0]
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        matches = re.findall(r'(\d+)[,]\s*[–ê-–ì]\)', name)
        if matches:
            return matches[0]
        
        # –î–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–∏–ø–∞ "–®–ü–ü (4-1,–ê)" - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ
        matches = re.findall(r'(\d+)-\d+', name)
        if matches:
            return matches[0]
        
        # –ò—â–µ–º –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ –≤ —Å–∫–æ–±–∫–∞—Ö
        matches = re.findall(r'\((\d+)\)', name)
        if matches:
            return matches[0]
        
        # –ò—â–µ–º –ª—é–±–æ–µ —á–∏—Å–ª–æ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        matches = re.findall(r'\b(\d+)\b', name)
        if matches:
            return matches[0]
            
        return None
    
    def extract_letter(self, name):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—É–∫–≤—ã (–ê, –ë, –í, –ì) –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"""
        # –ò—â–µ–º –±—É–∫–≤—É –≤ —Å–∫–æ–±–∫–∞—Ö –≤ –∫–æ–Ω—Ü–µ: (30,–ì) –∏–ª–∏ (–ê)
        matches = re.findall(r'\([^)]*([–ê-–ì])\)', name)
        if matches:
            return matches[0]
        
        # –ò—â–µ–º –±—É–∫–≤—É –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –≤ —Å–∫–æ–±–∫–∞—Ö
        matches = re.findall(r',\s*([–ê-–ì])\)', name)
        if matches:
            return matches[0]
        
        # –ò—â–µ–º –±—É–∫–≤—É –≤ —Å–∫–æ–±–∫–∞—Ö –æ—Ç–¥–µ–ª—å–Ω–æ
        matches = re.findall(r'\(([–ê-–ì])\)', name)
        if matches:
            return matches[0]
            
        return None
    
    def parse_protocol_sample_name(self, sample_name):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±—É–∫–≤—É –∏–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ (–ù–ê, –ù–ë, –ù–í, –ù–ì) - —ç—Ç–æ –Ω–∏—Ç–∫–∞!
        letter_map = {'–ù–ê': '–ê', '–ù–ë': '–ë', '–ù–í': '–í', '–ù–ì': '–ì', '–ù-–ì': '–ì'}
        letter = None
        
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –±—É–∫–≤—É –Ω–∏—Ç–∫–∏ –∏–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±)
        for prefix, mapped_letter in letter_map.items():
            if sample_name.startswith(prefix):
                letter = mapped_letter
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å—É, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
        if not letter:
            for l in self.letters:
                if f'–ù{l}' in sample_name or f'–ù-{l}' in sample_name:
                    letter = l
                    break
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Å —É—á–µ—Ç–æ–º —Ä–∏–º—Å–∫–∏—Ö —Ü–∏—Ñ—Ä)
        surface_type = None
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ä–∏–º—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã –Ω–∞ –∞—Ä–∞–±—Å–∫–∏–µ –¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏
        normalized_name = sample_name
        for roman, arabic in self.roman_to_arabic.items():
            normalized_name = normalized_name.replace(roman, arabic)
        
        for stype, patterns in self.surface_types.items():
            for pattern in patterns:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Ç–æ–∂–µ
                normalized_pattern = pattern
                for roman, arabic in self.roman_to_arabic.items():
                    normalized_pattern = normalized_pattern.replace(roman, arabic)
                
                if normalized_pattern in normalized_name:
                    surface_type = stype
                    break
            if surface_type:
                break
        
        # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ—Ç, –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ
        if not surface_type:
            for stype, patterns in self.surface_types.items():
                for pattern in patterns:
                    normalized_pattern = pattern
                    for roman, arabic in self.roman_to_arabic.items():
                        normalized_pattern = normalized_pattern.replace(roman, arabic)
                    
                    if self.similar(normalized_pattern, normalized_name) > 0.7:
                        surface_type = stype
                        break
                if surface_type:
                    break
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä —Ç—Ä—É–±—ã
        tube_number = None
        numbers = re.findall(r'\d+', sample_name)
        if numbers:
            # –ò—â–µ–º —á–∏—Å–ª–æ –ø–æ—Å–ª–µ "–ù–ì" –∏–ª–∏ –ø–æ–¥–æ–±–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
            pattern_match = re.search(r'–ù[–ê-–ì-]\s*(\d+)', sample_name)
            if pattern_match:
                tube_number = pattern_match.group(1)
            else:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –∫–∞–∫ –Ω–æ–º–µ—Ä —Ç—Ä—É–±—ã
                tube_number = numbers[0]
        
        return {
            'original': sample_name,
            'surface_type': surface_type,
            'tube_number': tube_number,
            'letter': letter
        }
    
    def match_samples(self, protocol_samples, correct_samples):
        """–ú–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤"""
        matched_samples = []
        unmatched_protocol = protocol_samples.copy()
        used_correct = set()
        
        # –≠—Ç–∞–ø 1: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ + –Ω–æ–º–µ—Ä–∞ + –±—É–∫–≤—ã
        matches_stage1 = self._match_stage1(unmatched_protocol, correct_samples, used_correct)
        matched_samples.extend(matches_stage1)
        unmatched_protocol = [s for s in unmatched_protocol if s not in [m[0] for m in matches_stage1]]
        
        # –≠—Ç–∞–ø 2: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ + –Ω–æ–º–µ—Ä–∞
        matches_stage2 = self._match_stage2(unmatched_protocol, correct_samples, used_correct)
        matched_samples.extend(matches_stage2)
        unmatched_protocol = [s for s in unmatched_protocol if s not in [m[0] for m in matches_stage2]]
        
        # –≠—Ç–∞–ø 3: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ + –±—É–∫–≤—ã
        matches_stage3 = self._match_stage3(unmatched_protocol, correct_samples, used_correct)
        matched_samples.extend(matches_stage3)
        unmatched_protocol = [s for s in unmatched_protocol if s not in [m[0] for m in matches_stage3]]
        
        # –≠—Ç–∞–ø 4: –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏
        matches_stage4 = self._match_stage4(unmatched_protocol, correct_samples, used_correct)
        matched_samples.extend(matches_stage4)
        unmatched_protocol = [s for s in unmatched_protocol if s not in [m[0] for m in matches_stage4]]
        
        return matched_samples, unmatched_protocol
    
    def _match_stage1(self, protocol_samples, correct_samples, used_correct):
        """–≠—Ç–∞–ø 1: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ + –Ω–æ–º–µ—Ä–∞ + –±—É–∫–≤—ã"""
        matches = []
        for protocol in protocol_samples:
            protocol_info = self.parse_protocol_sample_name(protocol['name'])
            best_match = None
            
            for correct in correct_samples:
                if correct['original'] in used_correct:
                    continue
                
                if (protocol_info['surface_type'] == correct['surface_type'] and
                    protocol_info['tube_number'] == correct['tube_number'] and
                    protocol_info['letter'] == correct['letter']):
                    best_match = correct
                    break
            
            if best_match:
                matches.append((protocol, best_match, "–≠—Ç–∞–ø 1: –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ"))
                used_correct.add(best_match['original'])
        
        return matches
    
    def _match_stage2(self, protocol_samples, correct_samples, used_correct):
        """–≠—Ç–∞–ø 2: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ + –Ω–æ–º–µ—Ä–∞"""
        matches = []
        for protocol in protocol_samples:
            protocol_info = self.parse_protocol_sample_name(protocol['name'])
            best_match = None
            
            for correct in correct_samples:
                if correct['original'] in used_correct:
                    continue
                
                if (protocol_info['surface_type'] == correct['surface_type'] and
                    protocol_info['tube_number'] == correct['tube_number']):
                    best_match = correct
                    break
            
            if best_match:
                matches.append((protocol, best_match, "–≠—Ç–∞–ø 2: —Ç–∏–ø+–Ω–æ–º–µ—Ä"))
                used_correct.add(best_match['original'])
        
        return matches
    
    def _match_stage3(self, protocol_samples, correct_samples, used_correct):
        """–≠—Ç–∞–ø 3: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ + –±—É–∫–≤—ã"""
        matches = []
        for protocol in protocol_samples:
            protocol_info = self.parse_protocol_sample_name(protocol['name'])
            best_match = None
            
            for correct in correct_samples:
                if correct['original'] in used_correct:
                    continue
                
                if (protocol_info['surface_type'] == correct['surface_type'] and
                    protocol_info['letter'] == correct['letter']):
                    best_match = correct
                    break
            
            if best_match:
                matches.append((protocol, best_match, "–≠—Ç–∞–ø 3: —Ç–∏–ø+–±—É–∫–≤–∞"))
                used_correct.add(best_match['original'])
        
        return matches
    
    def _match_stage4(self, protocol_samples, correct_samples, used_correct):
        """–≠—Ç–∞–ø 4: –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏"""
        matches = []
        for protocol in protocol_samples:
            protocol_info = self.parse_protocol_sample_name(protocol['name'])
            best_match = None
            best_similarity = 0
            
            for correct in correct_samples:
                if correct['original'] in used_correct:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–π –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π
                if protocol_info['surface_type'] and correct['surface_type']:
                    similarity = self.similar(protocol_info['surface_type'], correct['surface_type'])
                    if similarity > 0.7 and similarity > best_similarity:
                        best_similarity = similarity
                        best_match = correct
            
            if best_match:
                matches.append((protocol, best_match, f"–≠—Ç–∞–ø 4: –ø–æ—Ö–æ–∂–∏–π —Ç–∏–ø ({best_similarity:.2f})"))
                used_correct.add(best_match['original'])
        
        return matches

class ChemicalAnalyzer:
    def __init__(self):
        self.load_standards()
        self.name_matcher = SampleNameMatcher()
        
    def load_standards(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –∏–∑ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        self.standards = {
            "12–•1–ú–§": {
                "C": (0.10, 0.15),
                "Si": (0.17, 0.37),
                "Mn": (0.40, 0.70),
                "Cr": (0.90, 1.20),
                "Mo": (0.25, 0.35),
                "V": (0.15, 0.30),
                "Ni": (None, 0.25),
                "Cu": (None, 0.20),
                "S": (None, 0.025),
                "P": (None, 0.025),
                "source": "–¢–£ 14-3–†-55-2001"
            },
            "12–•18–ù12–¢": {
                "C": (None, 0.12),
                "Si": (None, 0.80),
                "Mn": (1.00, 2.00),
                "Cr": (17.00, 19.00),
                "Ni": (11.00, 13.00),
                "Ti": (None, 0.70),
                "Cu": (None, 0.30),
                "S": (None, 0.020),
                "P": (None, 0.035),
                "source": "–¢–£ 14-3–†-55-2001"
            },
            "—Å—Ç–∞–ª—å 20": {
                "C": (0.17, 0.24),
                "Si": (0.17, 0.37),
                "Mn": (0.35, 0.65),
                "Cr": (None, 0.25),
                "Ni": (None, 0.25),
                "Cu": (None, 0.30),
                "P": (None, 0.030),
                "S": (None, 0.025),
                "source": "–¢–£ 14-3–†-55-2001"
            },
            "–î–∏82": {
                "C": (0.08, 0.12),
                "Si": (None, 0.5),
                "Mn": (0.30, 0.60),
                "Cr": (8.60, 10.00),
                "Ni": (None, 0.70),
                "Mo": (0.60, 0.80),
                "V": (0.10, 0.20),
                "Nb": (0.10, 0.20),
                "Cu": (None, 0.30),
                "S": (None, 0.015),
                "P": (None, 0.03),
                "source": "–¢–£ 14-3–†-55-2001"
            },
            "–î–∏59": {
                "C": (0.06, 0.10),
                "Si": (1.8, 2.2),
                "Mn": (12.00, 13.50),
                "Cr": (11.50, 13.00),
                "Ni": (1.8, 2.5),
                "Nb": (0.60, 1.00),
                "Cu": (2.00, 2.50),
                "S": (None, 0.02),
                "P": (None, 0.03),
                "source": "–¢–£ 14-3–†-55-2001"
            }
        }
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å
        if os.path.exists("user_standards.json"):
            with open("user_standards.json", "r", encoding="utf-8") as f:
                user_std = json.load(f)
                self.standards.update(user_std)
    
    def save_user_standards(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤"""
        with open("user_standards.json", "w", encoding="utf-8") as f:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã (–Ω–µ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ)
            predefined = ["12–•1–ú–§", "12–•18–ù12–¢", "—Å—Ç–∞–ª—å 20", "–î–∏82", "–î–∏59"]
            user_standards = {k: v for k, v in self.standards.items() if k not in predefined}
            json.dump(user_standards, f, ensure_ascii=False, indent=2)
    
    def parse_protocol_file(self, file_content):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"""
        try:
            doc = Document(io.BytesIO(file_content))
            samples = []
            current_sample = None
            
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                
                # –ü–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞
                if "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞:" in text:
                    sample_name = text.split("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–∞:")[1].strip()
                    current_sample = {
                        "name": sample_name,
                        "steel_grade": None,
                        "composition": {}
                    }
                    samples.append(current_sample)
                
                # –ü–æ–∏—Å–∫ –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏ - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
                elif "–•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤ –º–µ—Ç–∞–ª–ª–∞ –æ–±—Ä–∞–∑—Ü–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –º–∞—Ä–∫–µ —Å—Ç–∞–ª–∏:" in text:
                    if current_sample:
                        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏ (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏)
                        grade_text = text.split("–º–∞—Ä–∫–µ —Å—Ç–∞–ª–∏:")[1].strip()
                        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ ** –≤–æ–∫—Ä—É–≥ –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏ –∏ –≤—Å–µ —á—Ç–æ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
                        grade_text = re.sub(r'\*+', '', grade_text).strip()
                        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –¥–æ –∑–∞–ø—è—Ç–æ–π (–æ—Å–Ω–æ–≤–Ω—É—é –º–∞—Ä–∫—É —Å—Ç–∞–ª–∏)
                        grade_text = grade_text.split(',')[0].strip()
                        current_sample["steel_grade"] = grade_text
            
            # –ü–∞—Ä—Å–∏–Ω–≥ —Ç–∞–±–ª–∏—Ü —Å —Ö–∏–º–∏—á–µ—Å–∫–∏–º —Å–æ—Å—Ç–∞–≤–æ–º
            for i, table in enumerate(doc.tables):
                if i < len(samples):
                    composition = self.parse_composition_table(table)
                    samples[i]["composition"] = composition
            
            return samples
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ñ–∞–π–ª–∞: {str(e)}")
            return []
    
    def parse_composition_table(self, table):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–∞–±–ª–∏—Ü—ã —Å —Ö–∏–º–∏—á–µ—Å–∫–∏–º —Å–æ—Å—Ç–∞–≤–æ–º - –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å—Ç—Ä–æ–∫–∞–º"""
        composition = {}
        
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∞–±–ª–∏—Ü—É –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
            table_data = []
            for row in table.rows:
                row_data = [cell.text.strip() for cell in row.cells]
                table_data.append(row_data)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ –∏–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫
            if len(table_data) < 13:
                st.warning(f"–¢–∞–±–ª–∏—Ü–∞ –∏–º–µ–µ—Ç —Ç–æ–ª—å–∫–æ {len(table_data)} —Å—Ç—Ä–æ–∫, –æ–∂–∏–¥–∞–ª–æ—Å—å –º–∏–Ω–∏–º—É–º 13")
                return composition
            
            # –°—Ç—Ä–æ–∫–∞ 0: –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            headers_row1 = table_data[0]
            # –°—Ç—Ä–æ–∫–∞ 5: —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø—ã
            values_row1 = table_data[5]
            
            # –°—Ç—Ä–æ–∫–∞ 7: –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤—Ç–æ—Ä–æ–π –≥—Ä—É–ø–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤  
            headers_row2 = table_data[7]
            # –°—Ç—Ä–æ–∫–∞ 12: —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ç–æ—Ä–æ–π –≥—Ä—É–ø–ø—ã
            values_row2 = table_data[12]
            
            # –í—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
            all_elements = ["C", "Si", "Mn", "P", "S", "Cr", "Mo", "Ni", 
                           "Cu", "Al", "Co", "Nb", "Ti", "V", "W", "Fe"]
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            for i, header in enumerate(headers_row1):
                if header in all_elements and i < len(values_row1):
                    value_str = values_row1[i]
                    try:
                        # –û—á–∏—â–∞–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
                        value_str = value_str.replace(',', '.').replace(' ', '')
                        if '¬±' in value_str:
                            value_str = value_str.split('¬±')[0]
                        value = float(value_str)
                        composition[header] = value
                    except (ValueError, IndexError):
                        continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ç–æ—Ä—É—é –≥—Ä—É–ø–ø—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            for i, header in enumerate(headers_row2):
                if header in all_elements and i < len(values_row2):
                    value_str = values_row2[i]
                    try:
                        # –û—á–∏—â–∞–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
                        value_str = value_str.replace(',', '.').replace(' ', '')
                        if '¬±' in value_str:
                            value_str = value_str.split('¬±')[0]
                        value = float(value_str)
                        composition[header] = value
                    except (ValueError, IndexError):
                        continue
            
            return composition
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–∞–±–ª–∏—Ü—ã: {str(e)}")
            return {}
    
    def match_sample_names(self, samples, correct_names_file):
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏"""
        if not correct_names_file:
            return samples, []
        
        correct_samples = self.name_matcher.parse_correct_names(correct_names_file.getvalue())
        
        if not correct_samples:
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤")
            return samples, []
        
        # –ú–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        matched_pairs, unmatched_protocol = self.name_matcher.match_samples(samples, correct_samples)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Å–ø–∏—Å–∫–∏
        matched_samples = []
        for protocol_sample, correct_sample, match_stage in matched_pairs:
            corrected_sample = protocol_sample.copy()
            corrected_sample['original_name'] = protocol_sample['name']
            corrected_sample['name'] = correct_sample['original']
            corrected_sample['correct_number'] = correct_sample['number']
            corrected_sample['automatically_matched'] = True
            corrected_sample['match_stage'] = match_stage
            matched_samples.append(corrected_sample)
        
        unmatched_samples = []
        for sample in unmatched_protocol:
            sample['original_name'] = sample['name']
            sample['correct_number'] = None
            sample['automatically_matched'] = False
            unmatched_samples.append(sample)
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏
        if matched_samples:
            st.success(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(matched_samples)} –æ–±—Ä–∞–∑—Ü–æ–≤")
            
            with st.expander("üìã –î–µ—Ç–∞–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"):
                match_data = []
                for sample in matched_samples:
                    protocol_info = self.name_matcher.parse_protocol_sample_name(sample['original_name'])
                    match_data.append({
                        '–ù–æ–º–µ—Ä': sample['correct_number'],
                        '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': sample['original_name'],
                        '–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': sample['name'],
                        '–≠—Ç–∞–ø': sample.get('match_stage', '–Ω/–¥'),
                        '–¢–∏–ø': protocol_info['surface_type'] or '–Ω/–¥',
                        '–¢—Ä—É–±–∞': protocol_info['tube_number'] or '–Ω/–¥',
                        '–ù–∏—Ç–∫–∞': protocol_info['letter'] or '–Ω/–¥'
                    })
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É
                match_data.sort(key=lambda x: x['–ù–æ–º–µ—Ä'])
                st.table(pd.DataFrame(match_data))
        
        if unmatched_samples:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å {len(unmatched_samples)} –æ–±—Ä–∞–∑—Ü–æ–≤")
            
            with st.expander("‚ö†Ô∏è –ü—Ä–æ—Å–º–æ—Ç—Ä –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤"):
                unmatched_data = []
                for sample in unmatched_samples:
                    protocol_info = self.name_matcher.parse_protocol_sample_name(sample['name'])
                    unmatched_data.append({
                        '–û–±—Ä–∞–∑–µ—Ü': sample['original_name'],
                        '–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏': sample['steel_grade'],
                        '–¢–∏–ø': protocol_info['surface_type'] or '–Ω/–¥',
                        '–¢—Ä—É–±–∞': protocol_info['tube_number'] or '–Ω/–¥',
                        '–ù–∏—Ç–∫–∞': protocol_info['letter'] or '–Ω/–¥'
                    })
                st.table(pd.DataFrame(unmatched_data))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –ø–æ –Ω–æ–º–µ—Ä—É, –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ü–µ
        matched_samples.sort(key=lambda x: x['correct_number'])
        return matched_samples + unmatched_samples, correct_samples
    
    def check_element_compliance(self, element, value, standard):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–∞–º"""
        if element not in standard or element == "source":
            return "normal"
        
        min_val, max_val = standard[element]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        if min_val is not None and value < min_val:
            return "deviation"
        elif max_val is not None and value > max_val:
            return "deviation"
        else:
            return "normal"
    
    def create_report_table_with_original_names(self, samples):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –æ—Ç—á–µ—Ç–∞"""
        if not samples:
            return None
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏
        steel_grades = list(set(sample["steel_grade"] for sample in samples if sample["steel_grade"]))
        
        tables = {}
        
        for grade in steel_grades:
            grade_samples = [s for s in samples if s["steel_grade"] == grade]
            
            if grade not in self.standards:
                st.warning(f"–ù–µ—Ç –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤ –¥–ª—è –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏: {grade}")
                continue
                
            standard = self.standards[grade]
            # –¢–æ–ª—å–∫–æ –Ω–æ—Ä–º–∏—Ä—É–µ–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–∏—Å–∫–ª—é—á–∞–µ–º 'source')
            norm_elements = [elem for elem in standard.keys() if elem != "source"]
            
            # –î–ª—è —Å—Ç–∞–ª–∏ 12–•1–ú–§ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Å–æ–±—ã–π –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤
            if grade == "12–•1–ú–§":
                main_elements = ["C", "Si", "Mn", "Cr", "Mo", "V", "Ni"]
                harmful_elements = ["Cu", "S", "P"]
                other_elements = [elem for elem in norm_elements if elem not in main_elements + harmful_elements]
                norm_elements = main_elements + other_elements + harmful_elements
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–∑—Ü—ã
            grade_samples_sorted = sorted(
                grade_samples,
                key=lambda x: (x.get('correct_number') is None, x.get('correct_number', float('inf')))
            )
            
            # –°–æ–∑–¥–∞–µ–º DataFrame
            data = []
            compliance_data = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑—Ü—ã —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π
            for idx, sample in enumerate(grade_samples_sorted, 1):
                display_number = idx
                
                row = {
                    "‚Ññ": display_number, 
                    "–û–±—Ä–∞–∑–µ—Ü": sample["name"]
                }
                compliance_row = {"‚Ññ": "normal", "–û–±—Ä–∞–∑–µ—Ü": "normal"}
                
                for elem in norm_elements:
                    if elem in sample["composition"]:
                        value = sample["composition"][elem]
                        if elem in ["S", "P"]:
                            row[elem] = f"{value:.3f}".replace('.', ',')
                        else:
                            row[elem] = f"{value:.2f}".replace('.', ',')
                        
                        status = self.check_element_compliance(elem, value, standard)
                        compliance_row[elem] = status
                    else:
                        row[elem] = "-"
                        compliance_row[elem] = "normal"
                
                data.append(row)
                compliance_data.append(compliance_row)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–∞–º–∏
            requirements_row = {"‚Ññ": "", "–û–±—Ä–∞–∑–µ—Ü": f"–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¢–£ 14-3–†-55-2001 –¥–ª—è —Å—Ç–∞–ª–∏ –º–∞—Ä–∫–∏ {grade}"}
            requirements_compliance = {"‚Ññ": "requirements", "–û–±—Ä–∞–∑–µ—Ü": "requirements"}
            
            for elem in norm_elements:
                min_val, max_val = standard[elem]
                if min_val is not None and max_val is not None:
                    if elem in ["S", "P"]:
                        requirements_row[elem] = f"{min_val:.3f}-{max_val:.3f}".replace('.', ',')
                    else:
                        requirements_row[elem] = f"{min_val:.2f}-{max_val:.2f}".replace('.', ',')
                elif min_val is not None:
                    if elem in ["S", "P"]:
                        requirements_row[elem] = f"‚â•{min_val:.3f}".replace('.', ',')
                    else:
                        requirements_row[elem] = f"‚â•{min_val:.2f}".replace('.', ',')
                elif max_val is not None:
                    if elem in ["S", "P"]:
                        requirements_row[elem] = f"‚â§{max_val:.3f}".replace('.', ',')
                    else:
                        requirements_row[elem] = f"‚â§{max_val:.2f}".replace('.', ',')
                else:
                    requirements_row[elem] = "–Ω–µ –Ω–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è"
                
                requirements_compliance[elem] = "requirements"
            
            data.append(requirements_row)
            compliance_data.append(requirements_compliance)
            
            tables[grade] = {
                "data": pd.DataFrame(data),
                "compliance": compliance_data,
                "columns_order": ["‚Ññ", "–û–±—Ä–∞–∑–µ—Ü"] + norm_elements
            }
        
        return tables

# –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (add_manual_matching_interface, apply_styling, set_font_times_new_roman, main, create_word_report) 
# –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –∫–æ–¥–µ

def add_manual_matching_interface(samples, correct_samples, analyzer):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä—É—á–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π –ø—Ä–æ–±–ª–µ–º"""
    st.header("üîß –†—É—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    editable_samples = samples.copy()
    correct_names_dict = {cs['original']: cs for cs in correct_samples}
    correct_names_list = [cs['original'] for cs in correct_samples]
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã
    conflict_candidates = {}
    for correct in correct_samples:
        potential_matches = []
        for sample in editable_samples:
            protocol_info = analyzer.name_matcher.parse_protocol_sample_name(sample['name'])
            if (protocol_info['surface_type'] == correct['surface_type'] and
                protocol_info['tube_number'] == correct['tube_number']):
                potential_matches.append(sample)
        
        if len(potential_matches) > 1:
            conflict_candidates[correct['original']] = potential_matches
    
    options = ["–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω"] + correct_names_list
    manual_matches = {}
    
    st.write("**–°–æ–ø–æ—Å—Ç–∞–≤—å—Ç–µ –æ–±—Ä–∞–∑—Ü—ã –≤—Ä—É—á–Ω—É—é:**")
    
    for i, sample in enumerate(editable_samples):
        col1, col2 = st.columns([2, 3])
        
        with col1:
            # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã
            is_conflict = any(sample in matches for matches in conflict_candidates.values())
            conflict_color = "üî¥" if is_conflict else "‚ö™"
            
            st.write(f"{conflict_color} **{sample.get('original_name', sample['name'])}**")
            if sample.get('steel_grade'):
                st.write(f"*–ú–∞—Ä–∫–∞: {sample['steel_grade']}*")
            
            protocol_info = analyzer.name_matcher.parse_protocol_sample_name(sample['name'])
            st.write(f"*–¢–∏–ø: {protocol_info['surface_type'] or '–Ω/–¥'}*")
            st.write(f"*–¢—Ä—É–±–∞: {protocol_info['tube_number'] or '–Ω/–¥'}*")
            st.write(f"*–ù–∏—Ç–∫–∞: {protocol_info['letter'] or '–Ω/–¥'}*")
            
            if is_conflict:
                st.warning("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è")
        
        with col2:
            current_match = sample['name'] if sample['name'] in correct_names_list else "–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω"
            
            selected = st.selectbox(
                f"–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞ {i+1}",
                options=options,
                index=options.index(current_match) if current_match in options else 0,
                key=f"manual_match_{i}"
            )
            
            if selected != "–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω":
                manual_matches[sample['name']] = selected
    
    if st.button("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ä—É—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"):
        updated_samples = []
        
        for sample in editable_samples:
            if sample['name'] in manual_matches:
                correct_name = manual_matches[sample['name']]
                correct_sample = correct_names_dict[correct_name]
                
                updated_sample = sample.copy()
                updated_sample['original_name'] = sample['name']
                updated_sample['name'] = correct_name
                updated_sample['correct_number'] = correct_sample['number']
                updated_sample['manually_matched'] = True
                
                updated_samples.append(updated_sample)
            else:
                sample['manually_matched'] = False
                updated_samples.append(sample)
        
        st.success(f"–†—É—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ! –û–±–Ω–æ–≤–ª–µ–Ω–æ {len(manual_matches)} –æ–±—Ä–∞–∑—Ü–æ–≤.")
        return updated_samples
    
    return editable_samples

def apply_styling(df, compliance_data):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∏–ª–∏ –∫ DataFrame –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏"""
    styled_df = df.copy()
    
    styles = []
    for i, row in df.iterrows():
        if i < len(compliance_data):
            compliance_row = compliance_data[i]
            for col in df.columns:
                if col in compliance_row:
                    status = compliance_row[col]
                    if status == "deviation":
                        styles.append(f"background-color: #ffcccc; color: #cc0000; font-weight: bold;")
                    elif status == "requirements":
                        styles.append(f"background-color: #f0f0f0; font-style: italic;")
                    else:
                        styles.append("")
                else:
                    styles.append("")
    
    styled = df.style
    for i in range(len(df)):
        for j, col in enumerate(df.columns):
            idx = i * len(df.columns) + j
            if idx < len(styles) and styles[idx]:
                styled = styled.set_properties(subset=(i, col), **{'css': styles[idx]})
    
    return styled

def set_font_times_new_roman(doc):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —à—Ä–∏—Ñ—Ç Times New Roman –¥–ª—è –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    styles = doc.styles
    for style in styles:
        if hasattr(style, 'font'):
            style.font.name = 'Times New Roman'
    
    for paragraph in doc.paragraphs:
        for run in paragraph.runs:
            run.font.name = 'Times New Roman'
    
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    for run in paragraph.runs:
                        run.font.name = 'Times New Roman'

def main():
    st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ö–∏–º—Å–æ—Å—Ç–∞–≤–∞ –º–µ—Ç–∞–ª–ª–∞", layout="wide")
    st.title("üî¨ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞ –º–µ—Ç–∞–ª–ª–∞")
    
    analyzer = ChemicalAnalyzer()
    
    # –°–∞–π–¥–±–∞—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–∞–º–∏
    with st.sidebar:
        st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–∞–º–∏")
        
        st.subheader("–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏")
        selected_standard = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–∞—Ä–∫—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            options=list(analyzer.standards.keys())
        )
        
        if selected_standard:
            st.write(f"**–ù–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è {selected_standard}:**")
            standard = analyzer.standards[selected_standard]
            for elem, value_range in standard.items():
                if elem == "source":
                    continue
                
                if isinstance(value_range, tuple) and len(value_range) == 2:
                    min_val, max_val = value_range
                    if min_val is not None and max_val is not None:
                        st.write(f"- {elem}: {min_val:.3f} - {max_val:.3f}")
                    elif min_val is not None:
                        st.write(f"- {elem}: ‚â• {min_val:.3f}")
                    elif max_val is not None:
                        st.write(f"- {elem}: ‚â§ {max_val:.3f}")
            st.write(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {standard.get('source', '–Ω–µ —É–∫–∞–∑–∞–Ω')}")
        
        st.divider()
        
        st.subheader("–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –º–∞—Ä–∫—É —Å—Ç–∞–ª–∏")
        
        new_grade = st.text_input("–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏")
        new_source = st.text_input("–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç", value="–¢–£ 14-3–†-55-2001")
        
        if new_grade:
            st.write("**–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤:**")
            
            if 'elements' not in st.session_state:
                st.session_state.elements = []
            
            col1, col2, col3 = st.columns([2, 1, 1])
            with col1:
                new_element = st.text_input("–≠–ª–µ–º–µ–Ω—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä: Nb, W, B)", key="new_element")
            with col2:
                new_min = st.number_input("–ú–∏–Ω. –∑–Ω–∞—á–µ–Ω–∏–µ", value=0.0, format="%.3f", key="new_min")
            with col3:
                new_max = st.number_input("–ú–∞–∫—Å. –∑–Ω–∞—á–µ–Ω–∏–µ", value=0.0, format="%.3f", key="new_max")
            
            if st.button("–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç") and new_element:
                st.session_state.elements.append({
                    "element": new_element.strip().upper(),
                    "min": new_min if new_min > 0 else None,
                    "max": new_max if new_max > 0 else None
                })
            
            if st.session_state.elements:
                st.write("–î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:")
                elements_to_remove = []
                
                for i, elem_data in enumerate(st.session_state.elements):
                    col1, col2, col3, col4 = st.columns([3, 2, 2, 1])
                    with col1:
                        st.write(f"**{elem_data['element']}**")
                    with col2:
                        min_val = elem_data['min']
                        st.write(f"–ú–∏–Ω: {min_val:.3f}" if min_val else "–ú–∏–Ω: –Ω–µ –Ω–æ—Ä–º.")
                    with col3:
                        max_val = elem_data['max']
                        st.write(f"–ú–∞–∫—Å: {max_val:.3f}" if max_val else "–ú–∞–∫—Å: –Ω–µ –Ω–æ—Ä–º.")
                    with col4:
                        if st.button("‚ùå", key=f"del_{i}"):
                            elements_to_remove.append(i)
                
                for i in sorted(elements_to_remove, reverse=True):
                    st.session_state.elements.pop(i)
            
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤"):
                if not st.session_state.elements:
                    st.error("–î–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç!")
                elif new_grade in analyzer.standards:
                    st.error(f"–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏ {new_grade} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                else:
                    elements_ranges = {}
                    for elem_data in st.session_state.elements:
                        elements_ranges[elem_data["element"]] = (
                            elem_data["min"], 
                            elem_data["max"]
                        )
                    
                    elements_ranges["source"] = new_source
                    analyzer.standards[new_grade] = elements_ranges
                    analyzer.save_user_standards()
                    
                    st.session_state.elements = []
                    st.success(f"–ù–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è {new_grade} —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
    st.header("–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
    
    st.subheader("1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –æ–±—Ä–∞–∑—Ü–æ–≤")
    correct_names_file = st.file_uploader(
        "–§–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ (.docx)",
        type=["docx"],
        key="correct_names"
    )
    
    correct_samples = []
    if correct_names_file:
        correct_samples = analyzer.name_matcher.parse_correct_names(correct_names_file.getvalue())
        if correct_samples:
            st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(correct_samples)} –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –æ–±—Ä–∞–∑—Ü–æ–≤")
            with st.expander("üìã –ü—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π"):
                preview_data = []
                for sample in correct_samples:
                    preview_data.append({
                        '–ù–æ–º–µ—Ä': sample['number'],
                        '–ù–∞–∑–≤–∞–Ω–∏–µ': sample['original'],
                        '–¢–∏–ø': sample['surface_type'] or '–Ω/–¥',
                        '–¢—Ä—É–±–∞': sample['tube_number'] or '–Ω/–¥', 
                        '–ù–∏—Ç–∫–∞': sample['letter'] or '–Ω/–¥'
                    })
                st.table(pd.DataFrame(preview_data))
    
    st.subheader("2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    uploaded_files = st.file_uploader(
        "–§–∞–π–ª—ã –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ (.docx)", 
        type=["docx"], 
        accept_multiple_files=True,
        key="protocol_files"
    )
    
    all_samples = []
    
    if uploaded_files:
        for uploaded_file in uploaded_files:
            samples = analyzer.parse_protocol_file(uploaded_file.getvalue())
            all_samples.extend(samples)
        
        if correct_names_file and correct_samples:
            st.subheader("üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –æ–±—Ä–∞–∑—Ü–æ–≤")
            all_samples, correct_samples_loaded = analyzer.match_sample_names(all_samples, correct_names_file)
            
            all_samples = add_manual_matching_interface(all_samples, correct_samples_loaded, analyzer)
        
        if all_samples:
            st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
            
            st.markdown("""
            **–õ–µ–≥–µ–Ω–¥–∞:**
            - <span style='background-color: #ffcccc; padding: 2px 5px; border-radius: 3px;'>üî¥ –ö—Ä–∞—Å–Ω—ã–π</span> - –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –Ω–æ—Ä–º
            - <span style='background-color: #f0f0f0; padding: 2px 5px; border-radius: 3px;'>‚ö™ –°–µ—Ä—ã–π</span> - –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
            """, unsafe_allow_html=True)
            
            report_tables = analyzer.create_report_table_with_original_names(all_samples)
            
            export_tables = {}
            
            if report_tables:
                for grade, table_data in report_tables.items():
                    st.subheader(f"–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏: {grade}")
                    
                    styled_table = apply_styling(table_data["data"], table_data["compliance"])
                    st.dataframe(styled_table, use_container_width=True, hide_index=True)
                    
                    export_tables[grade] = table_data["data"]
                
                if st.button("üìÑ –≠–∫—Å–ø–æ—Ä—Ç –≤ Word"):
                    create_word_report(export_tables, all_samples, analyzer)
                    st.success("–û—Ç—á–µ—Ç –≥–æ—Ç–æ–≤ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é!")
            
            st.header("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã")
            for sample in all_samples:
                with st.expander(f"üìã {sample['name']} - {sample['steel_grade']}"):
                    if 'original_name' in sample:
                        st.write(f"**–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ:** {sample['original_name']}")
                    if 'correct_number' in sample:
                        st.write(f"**–ù–æ–º–µ—Ä –≤ —Å–ø–∏—Å–∫–µ:** {sample['correct_number']}")
                    st.write(f"**–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏:** {sample['steel_grade']}")
                    st.write("**–•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤:**")
                    for element, value in sample['composition'].items():
                        st.write(f"- {element}: {value}")

def create_word_report(tables, samples, analyzer):
    """–°–æ–∑–¥–∞–Ω–∏–µ Word –æ—Ç—á–µ—Ç–∞"""
    try:
        doc = Document()
        
        set_font_times_new_roman(doc)
        
        title = doc.add_heading('–ü—Ä–æ—Ç–æ–∫–æ–ª –∞–Ω–∞–ª–∏–∑–∞ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        doc.add_paragraph(f"–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è: {datetime.now().strftime('%d.%m.%Y %H:%M')}")
        doc.add_paragraph(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(samples)}")
        doc.add_paragraph("")
        
        doc.add_heading('–õ–µ–≥–µ–Ω–¥–∞', level=1)
        legend_table = doc.add_table(rows=3, cols=2)
        legend_table.style = 'Table Grid'
        
        legend_table.cell(0, 0).text = "–¶–≤–µ—Ç"
        legend_table.cell(0, 1).text = "–ó–Ω–∞—á–µ–Ω–∏–µ"
        
        legend_table.cell(1, 0).text = "üî¥"
        legend_table.cell(1, 1).text = "–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –Ω–æ—Ä–º"
        
        legend_table.cell(2, 0).text = "‚ö™"
        legend_table.cell(2, 1).text = "–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è"
        
        doc.add_paragraph()
        
        for grade, table_df in tables.items():
            doc.add_heading(f'–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏: {grade}', level=1)
            
            word_table = doc.add_table(rows=len(table_df)+1, cols=len(table_df.columns))
            word_table.style = 'Table Grid'
            
            for j, col in enumerate(table_df.columns):
                word_table.cell(0, j).text = str(col)
            
            for i, row in table_df.iterrows():
                for j, col in enumerate(table_df.columns):
                    word_table.cell(i+1, j).text = str(row[col])
            
            doc.add_paragraph()
        
        doc.save("—Ö–∏–º–∏—á–µ—Å–∫–∏–π_–∞–Ω–∞–ª–∏–∑_–æ—Ç—á–µ—Ç.docx")
        
        with open("—Ö–∏–º–∏—á–µ—Å–∫–∏–π_–∞–Ω–∞–ª–∏–∑_–æ—Ç—á–µ—Ç.docx", "rb") as file:
            btn = st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç",
                data=file,
                file_name="—Ö–∏–º–∏—á–µ—Å–∫–∏–π_–∞–Ω–∞–ª–∏–∑_–æ—Ç—á–µ—Ç.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Word –æ—Ç—á–µ—Ç–∞: {str(e)}")

if __name__ == "__main__":
    main()
